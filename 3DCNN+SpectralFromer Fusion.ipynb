{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SE network pytorch implementation from Start\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Imports\n",
    "import argparse\n",
    "import collections\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import geniter1_disjoint\n",
    "import record\n",
    "import Utils1\n",
    "\n",
    "#import torch_optimizer as optim2   \"\"\"torch_optimizer is not present in the Env\"\"\"\n",
    "\n",
    "from torchsummary import summary\n",
    "from vit_pytorch_ours import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling(proportion, ground_truth):\n",
    "    train = {}\n",
    "    test = {}\n",
    "    labels_loc = {}\n",
    "    m = max(ground_truth)\n",
    "    for i in range(m):\n",
    "        indexes = [\n",
    "            j for j, x in enumerate(ground_truth.ravel().tolist())\n",
    "            if x == i + 1\n",
    "        ]\n",
    "        np.random.shuffle(indexes)\n",
    "        labels_loc[i] = indexes\n",
    "        if proportion != 1:\n",
    "            nb_val = max(int((1 - proportion) * len(indexes)), 3)\n",
    "        else:\n",
    "            nb_val = 0\n",
    "        train[i] = indexes[:nb_val]\n",
    "        test[i] = indexes[nb_val:]\n",
    "    train_indexes = []\n",
    "    test_indexes = []\n",
    "    for i in range(m):\n",
    "        train_indexes += train[i]\n",
    "        test_indexes += test[i]\n",
    "    np.random.shuffle(train_indexes)\n",
    "    np.random.shuffle(test_indexes)\n",
    "    return train_indexes, test_indexes\n",
    "\n",
    "\n",
    "\n",
    "def shuffle_data(data_hsi, gt_hsi):\n",
    "    data_hsi_shuffle = np.zeros((data_hsi.shape[0], data_hsi.shape[1], data_hsi.shape[2], data_hsi.shape[3]))\n",
    "    gt_hsi_shuffle = np.zeros(data_hsi.shape[0])\n",
    "    _, total_indexes = sampling(1, gt_hsi)\n",
    "    for i in range(len(total_indexes)):\n",
    "        data_hsi_shuffle[i] = data_hsi[total_indexes[i],:,:,:]\n",
    "        gt_hsi_shuffle[i] = gt_hsi[total_indexes[i]] \n",
    "    gt_hsi_shuffle = gt_hsi_shuffle.astype(int) \n",
    "    return data_hsi_shuffle, gt_hsi_shuffle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAM_DATASET = 'IN'\n",
    "PARAM_EPOCH = 70\n",
    "PARAM_ITER = 3    # number of iterations the model is trained and tested\n",
    "PATCH_SIZE = 2     # HSI patch/window size = 2*PATCH_SIZE +1\n",
    "PARAM_VAL = 0.2    \n",
    "PARAM_OPTIM = 'adam'\n",
    "batch_size = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(Dataset, split=0.7):\n",
    "    data_path = '/home/sankar/Crop_dataset/data/'     # data path\n",
    "    data_hsi = np.load(data_path + 'X_train_10Crops_patch11_.npy')   # reading the data\n",
    "    gt_hsi = np.load(data_path + 'y_train_10Crops_patch11_.npy')   # reading labels \n",
    "  \n",
    "    gt_hsi = gt_hsi.astype(int) \n",
    "    data_hsi, gt_hsi = shuffle_data(data_hsi, gt_hsi)\n",
    "    \n",
    "    K = data_hsi.shape[2]\n",
    "    TOTAL_SIZE = np.count_nonzero(np.asarray(gt_hsi))\n",
    "    \n",
    "    VALIDATION_SPLIT = split\n",
    "    TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
    "   \n",
    "    \n",
    "    return data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE, VALIDATION_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Loading\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# for Monte Carlo runs\n",
    "seeds = [1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341]\n",
    "ensemble = 1\n",
    "\n",
    "global Dataset  # UP,IN,SV, KSC\n",
    "dataset = PARAM_DATASET  #input('Please input the name of Dataset(IN, UP, SV, KSC):')\n",
    "Dataset = dataset.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2176, 25, 25, 220)\n",
      "(1360000, 220)\n",
      "The class numbers of the HSI data is: 4\n"
     ]
    }
   ],
   "source": [
    "# # Pytorch Data Loader Creation\n",
    "data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE, VALIDATION_SPLIT = load_dataset(\n",
    "    Dataset, PARAM_VAL)\n",
    "print(data_hsi.shape)\n",
    "tot_samples, image_x, image_y, BAND = data_hsi.shape\n",
    "\n",
    "#data = data_hsi\n",
    "data = data_hsi.reshape(\n",
    "np.prod(data_hsi.shape[:3]), np.prod(data_hsi.shape[3:]))\n",
    "print(data.shape)\n",
    "gt = gt_hsi \n",
    "\n",
    "CLASSES_NUM = max(gt_hsi)\n",
    "#CLASSES_NUM = CLASSES_NUM. astype(int)\n",
    "print('The class numbers of the HSI data is:', CLASSES_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Importing Setting Parameters-----\n",
      "1740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2176, 436, 1740)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('-----Importing Setting Parameters-----')\n",
    "ITER = PARAM_ITER\n",
    "PATCH_LENGTH = PATCH_SIZE\n",
    "lr, num_epochs, batch_size = 0.001, 11, batch_size\n",
    "loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "img_rows = 2 * PATCH_LENGTH + 1\n",
    "img_cols = 2 * PATCH_LENGTH + 1\n",
    "img_channels = data_hsi.shape[3]\n",
    "INPUT_DIMENSION = data_hsi.shape[3]\n",
    "ALL_SIZE = data_hsi.shape[0] \n",
    "\n",
    "VAL_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
    "print(VAL_SIZE)\n",
    "ALL_SIZE, TRAIN_SIZE, VAL_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2176, 25, 25, 220)\n"
     ]
    }
   ],
   "source": [
    "KAPPA = []\n",
    "OA = []\n",
    "AA = []\n",
    "TRAINING_TIME = []\n",
    "TESTING_TIME = []\n",
    "ELEMENT_ACC = np.zeros((ITER, CLASSES_NUM))\n",
    "ELEMENT_ACC.shape\n",
    "data.shape\n",
    "data = preprocessing.scale(data)\n",
    "\n",
    "data_ = data.reshape(data_hsi.shape[0], data_hsi.shape[1], data_hsi.shape[2], data_hsi.shape[3] )\n",
    "print(data_.shape)\n",
    "whole_data = data_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Test Data Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_test(Dataset, split=0.99):\n",
    "    data_path = '/home/sankar/Crop_dataset/data/'   \n",
    "    data_hsi = np.load(data_path + 'X_test_10Crops_patch11_.npy')   \n",
    "    data_hsi = data_hsi[:, 2:7, 2:7, :]\n",
    "    gt_hsi = np.load(data_path + 'y_test_10Crops_patch11_.npy')   \n",
    "\n",
    "    gt_hsi = gt_hsi.astype(int) \n",
    "    data_hsi, gt_hsi = shuffle_data(data_hsi, gt_hsi)\n",
    "    \n",
    "    K = data_hsi.shape[2]\n",
    "    TOTAL_SIZE = np.count_nonzero(np.asarray(gt_hsi))\n",
    "    \n",
    "    VALIDATION_SPLIT = split\n",
    "    TRAIN_SIZE = math.ceil(TOTAL_SIZE * VALIDATION_SPLIT)\n",
    "   \n",
    "    \n",
    "    return data_hsi, gt_hsi, TOTAL_SIZE, TRAIN_SIZE, VALIDATION_SPLIT\n",
    "\n",
    "# # Pytorch Data Loader Creation\n",
    "data_hsi_disj, gt_hsi_disj, _, _, _ = load_dataset_test(Dataset, 0.99)\n",
    "print(data_hsi_disj.shape)\n",
    "data_disj = data_hsi_disj.reshape(np.prod(data_hsi_disj.shape[:3]), np.prod(data_hsi_disj.shape[3:]))\n",
    "data_disj = preprocessing.scale(data_disj)\n",
    "whole_data_disj = data_disj.reshape(data_hsi_disj.shape[0], data_hsi_disj.shape[1], data_hsi_disj.shape[2], data_hsi_disj.shape[3] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,\n",
    "          train_iter,\n",
    "          valida_iter,\n",
    "          loss,\n",
    "          optimizer,\n",
    "          device,\n",
    "          epochs,\n",
    "          early_stopping=True,\n",
    "          early_num=20):\n",
    "    loss_list = [100]\n",
    "    early_epoch = 0\n",
    "\n",
    "    net = net.to(device)\n",
    "    print(\"training on \", device)\n",
    "    start = time.time()\n",
    "    train_loss_list = []\n",
    "    valida_loss_list = []\n",
    "    train_acc_list = []\n",
    "    valida_acc_list = []\n",
    "    for epoch in range(epochs):\n",
    "        train_acc_sum, n = 0.0, 0\n",
    "        time_epoch = time.time()\n",
    "        lr_adjust = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "            optimizer, 15, eta_min=0.0, last_epoch=-1)\n",
    "        for X, y in train_iter:\n",
    "\n",
    "            batch_count, train_l_sum = 0, 0\n",
    "            #X = X.permute(0, 3, 1, 2)\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            y_hat = net(X)\n",
    "            # print('y_hat', y_hat)\n",
    "            # print('y', y)\n",
    "            l = loss(y_hat, y.long())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            train_l_sum += l.cpu().item()\n",
    "            train_acc_sum += (y_hat.argmax(dim=1) == y).sum().cpu().item()\n",
    "            n += y.shape[0]\n",
    "            batch_count += 1\n",
    "        lr_adjust.step()\n",
    "        valida_acc, valida_loss = record.evaluate_accuracy(\n",
    "            valida_iter, net, loss, device)\n",
    "        loss_list.append(valida_loss)\n",
    "\n",
    "        train_loss_list.append(train_l_sum)  # / batch_count)\n",
    "        train_acc_list.append(train_acc_sum / n)\n",
    "        valida_loss_list.append(valida_loss)\n",
    "        valida_acc_list.append(valida_acc)\n",
    "\n",
    "        print(\n",
    "            'epoch %d, train loss %.6f, train acc %.3f, valida loss %.6f, valida acc %.3f, time %.1f sec'\n",
    "            % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n,\n",
    "               valida_loss, valida_acc, time.time() - time_epoch))\n",
    "\n",
    "        PATH = \"./3DCNN_ViT.pt\"\n",
    "        # if loss_list[-1] <= 0.01 and valida_acc >= 0.95:\n",
    "        #     torch.save(net.state_dict(), PATH)\n",
    "        #     break\n",
    "\n",
    "        if early_stopping and loss_list[-2] < loss_list[-1]:\n",
    "            if early_epoch == 0:  # and valida_acc > 0.9:\n",
    "                torch.save(net.state_dict(), PATH)\n",
    "            early_epoch += 1\n",
    "            loss_list[-1] = loss_list[-2]\n",
    "            if early_epoch == early_num:\n",
    "                net.load_state_dict(torch.load(PATH))\n",
    "                break\n",
    "        else:\n",
    "            early_epoch = 0\n",
    "\n",
    "    print('epoch %d, loss %.4f, train acc %.3f, time %.1f sec'\n",
    "          % (epoch + 1, train_l_sum / batch_count, train_acc_sum / n,\n",
    "             time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mode = 'ViT' #'ViT'   'CAF'\n",
    "num_classes = 10\n",
    "depth = 5\n",
    "near_band = 1\n",
    "image_size = 5  # patch or window size\n",
    "batch_size = 32\n",
    "num_patches = 300 # number of channels in the HSI\n",
    "PARAM_EPOCH = 65\n",
    "\n",
    "from vit_pytorch_ours import ViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 0\n",
      "Train size:  7943\n",
      "Validation size:  1988\n",
      "-----Selecting Small Pieces from the Original Cube Data-----\n",
      "(7943, 5, 5, 300) (7943,)\n",
      "Test data shape:\n",
      "(8330, 5, 5, 300) (8330,)\n",
      "training on  cuda\n",
      "epoch 1, train loss 0.278873, train acc 0.622, valida loss 0.185540, valida acc 0.830, time 6.4 sec\n",
      "epoch 2, train loss 0.319461, train acc 0.844, valida loss 0.619777, valida acc 0.900, time 6.7 sec\n",
      "epoch 3, train loss 0.167643, train acc 0.897, valida loss 0.294037, valida acc 0.933, time 6.5 sec\n",
      "epoch 4, train loss 0.090859, train acc 0.931, valida loss 0.635709, valida acc 0.958, time 6.5 sec\n",
      "epoch 5, train loss 0.033730, train acc 0.944, valida loss 0.533309, valida acc 0.971, time 6.5 sec\n",
      "epoch 6, train loss 0.207132, train acc 0.959, valida loss 0.853393, valida acc 0.957, time 6.6 sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m test_iter_disj \u001b[38;5;241m=\u001b[39m geniter1_disjoint\u001b[38;5;241m.\u001b[39mgenerate_iter_test(TEST_SIZE_disj, test_indices_disj, whole_data_disj, PATCH_LENGTH, INPUT_DIMENSION, batch_size, gt_hsi_disj) \u001b[38;5;66;03m#batchsize in 1\u001b[39;00m\n\u001b[1;32m     45\u001b[0m tic1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m---> 46\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalida_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPARAM_EPOCH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m toc1 \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m     56\u001b[0m pred_test \u001b[38;5;241m=\u001b[39m []\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, valida_iter, loss, optimizer, device, epochs, early_stopping, early_num)\u001b[0m\n\u001b[1;32m     29\u001b[0m X \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     30\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 31\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# print('y_hat', y_hat)\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# print('y', y)\u001b[39;00m\n\u001b[1;32m     34\u001b[0m l \u001b[38;5;241m=\u001b[39m loss(y_hat, y\u001b[38;5;241m.\u001b[39mlong())\n",
      "File \u001b[0;32m~/anaconda3/envs/ptenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Crop_dataset/IEEE_TGRS_SpectralFormer-main/vit_pytorch.py:155\u001b[0m, in \u001b[0;36mViT.forward\u001b[0;34m(self, input_tensor, mask)\u001b[0m\n\u001b[1;32m    152\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_latent(x[:,\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# MLP classification layer\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmlp_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/ptenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ptenv/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/ptenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/anaconda3/envs/ptenv/lib/python3.8/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# # Training\n",
    "for index_iter in range(ITER):\n",
    "    print('iter:', index_iter)\n",
    "    # define the model\n",
    "    net = model = ViT(image_size = image_size, near_band = near_band, num_patches = num_patches, num_classes = num_classes, dim = 64, depth = depth, heads = 4, mlp_dim = 8, dropout = 0.1, emb_dropout = 0.1, mode = mode )\n",
    "\n",
    "    if PARAM_OPTIM == 'diffgrad':\n",
    "        optimizer = optim2.DiffGrad(\n",
    "            net.parameters(),\n",
    "            lr=lr,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8,\n",
    "            weight_decay=0)  # weight_decay=0.0001)\n",
    "    if PARAM_OPTIM == 'adam':\n",
    "        optimizer = optim.Adam(\n",
    "            net.parameters(),\n",
    "            lr=1e-3,\n",
    "            betas=(0.9, 0.999),\n",
    "            eps=1e-8,\n",
    "            weight_decay=0)\n",
    "    time_1 = int(time.time())\n",
    "    np.random.seed(seeds[index_iter])\n",
    "    # train_indices, test_indices = select(gt)\n",
    "    train_indices, test_indices = sampling(VALIDATION_SPLIT, gt)\n",
    "    _, total_indices = sampling(1, gt)\n",
    "\n",
    "    TRAIN_SIZE = len(train_indices)\n",
    "    print('Train size: ', TRAIN_SIZE)\n",
    "    TEST_SIZE = TOTAL_SIZE - TRAIN_SIZE\n",
    "    VAL_SIZE = TEST_SIZE\n",
    "    print('Validation size: ', VAL_SIZE)\n",
    "\n",
    "    print('-----Selecting Small Pieces from the Original Cube Data-----')\n",
    "    train_iter, test_iter, all_iter = geniter1_disjoint.generate_iter(\n",
    "        TRAIN_SIZE, train_indices, TEST_SIZE, test_indices, TOTAL_SIZE,\n",
    "        total_indices, whole_data, PATCH_LENGTH, INPUT_DIMENSION, batch_size, gt) #batchsize in 1\n",
    "    valida_iter = test_iter\n",
    "\n",
    "\n",
    "\n",
    "    _, test_indices_disj = sampling(0.99, gt_hsi_disj)\n",
    "    TEST_SIZE_disj = len(test_indices_disj)\n",
    "    test_iter_disj = geniter1_disjoint.generate_iter_test(TEST_SIZE_disj, test_indices_disj, whole_data_disj, PATCH_LENGTH, INPUT_DIMENSION, batch_size, gt_hsi_disj) #batchsize in 1\n",
    "\n",
    "    tic1 = time.time()\n",
    "    train(\n",
    "        net,\n",
    "        train_iter,\n",
    "        valida_iter,\n",
    "        loss,\n",
    "        optimizer,\n",
    "        device,\n",
    "        epochs=PARAM_EPOCH)\n",
    "    toc1 = time.time()\n",
    "\n",
    "    pred_test = []\n",
    "    y_test= []\n",
    "    tic2 = time.time()\n",
    "    with torch.no_grad():\n",
    "        for X, y in test_iter_disj:\n",
    "            X = X.to(device)\n",
    "            net.eval()\n",
    "            y_hat = net(X)\n",
    "            pred_test.extend(np.array(net(X).cpu().argmax(axis=1)))\n",
    "            y_test.extend(np.array(y))\n",
    "    toc2 = time.time()\n",
    "    collections.Counter(pred_test)\n",
    "    \n",
    "    gt_test = y_test  # gt_hsi_disj[test_indices_disj] - 1  \n",
    "    overall_acc = metrics.accuracy_score(gt_test, pred_test)\n",
    "    confusion_matrix = metrics.confusion_matrix(gt_test, pred_test)\n",
    "    each_acc, average_acc = record.aa_and_each_accuracy(confusion_matrix)\n",
    "    kappa = metrics.cohen_kappa_score(gt_test, pred_test)\n",
    "    \n",
    "    torch.save(net.state_dict(), '3DCNN_ViT_Net' + str(round(overall_acc, 3)) + '.pt')\n",
    "    KAPPA.append(kappa)\n",
    "    OA.append(overall_acc)\n",
    "    AA.append(average_acc)\n",
    "    TRAINING_TIME.append(toc1 - tic1)\n",
    "    TESTING_TIME.append(toc2 - tic2)\n",
    "    ELEMENT_ACC[index_iter, :] = each_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9787515006002401, 0.955702280912365, 0.9900360144057623, 0.99015606242497, 0.9991596638655462, 0.9926770708283313] [0.9869938883396692, 0.9732195638662994, 0.9933460834769082, 0.9936541805345698, 0.9989880698778449, 0.9950823306216297] [0.9718393122788036, 0.9417227958519832, 0.9867537262533065, 0.986917783576902, 0.9988807687412357, 0.9902609502976503] [[1.         0.9421572  0.99793388 1.         0.99487836]\n",
      " [0.99867725 0.88159238 0.98966942 1.         0.99615877]\n",
      " [0.9973545  0.97754338 0.99311295 1.         0.99871959]\n",
      " [0.99955908 0.97550187 0.99449036 1.         0.99871959]\n",
      " [0.99955908 0.9993195  0.99862259 1.         0.99743918]\n",
      " [1.         0.98298741 0.99242424 1.         1.        ]]\n",
      "On PaviaU Data set\n",
      "OA is:0.9844137655062024+/-0.014181666458907251\n",
      "AA is:0.9902140194528202+/-0.008381623876917833\n",
      "KAPPA is:0.9793958894999802+/-0.018640415596613204\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######Groundnut with ViT+3D CNN\n",
    "print(OA, AA, KAPPA, ELEMENT_ACC) #, confusion_matrix\n",
    "print(\"On PaviaU Data set\")\n",
    "print('OA is:' + str(np.mean(OA)) + '+/-'+ str(np.std(OA))),\n",
    "print('AA is:' + str(np.mean(AA)) + '+/-'+ str(np.std(AA))),\n",
    "print('KAPPA is:' + str(np.mean(KAPPA)) + '+/-'+ str(np.std(KAPPA))),\n",
    "# print('Train time:' + str(np.mean(TRAINING_TIME)) + '+/-'+ str(np.std(TRAINING_TIME))),\n",
    "# print('TESTING_TIME time:' + str(np.mean(TESTING_TIME)) + '+/-'+ str(np.std(TESTING_TIME))),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
